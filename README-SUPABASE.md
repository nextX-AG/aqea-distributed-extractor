# ðŸ—„ï¸ Supabase Setup fÃ¼r AQEA Distributed Extractor

Diese Anleitung zeigt, wie Sie Supabase als zentrale Datenbank fÃ¼r das AQEA Distributed Extractor System einrichten.

## ðŸŽ¯ **Warum Supabase?**

**Zentrale Datenbank fÃ¼r alle Worker:**
- âœ… **Ein Datenbank** statt N lokale Datenbanken 
- âœ… **Keine Duplikate** durch zentrale AQEA-Adressvergabe
- âœ… **Real-time Monitoring** aller Worker gleichzeitig
- âœ… **Multi-Cloud Ready** - Worker aus verschiedenen Providern
- âœ… **Kosteneffizient** - â‚¬0-25/Monat statt â‚¬100+ fÃ¼r eigene DB-Server

## ðŸ“‹ **Schritt-fÃ¼r-Schritt Setup**

### 1. Supabase Projekt erstellen

```bash
# 1. Gehe zu https://supabase.com
# 2. Klicke "Start your project" 
# 3. Erstelle ein neues Projekt:
#    - Name: aqea-distributed-extractor
#    - Region: Europe (Central) fÃ¼r deutsche Extraktion
#    - Passwort: [Starkes Passwort generieren]
```

### 2. Datenbank-Schema einrichten

```bash
# 1. Gehe zu deinem Supabase Projekt Dashboard
# 2. Klicke "SQL Editor" im SeitenmenÃ¼
# 3. Kopiere den kompletten Inhalt von scripts/init-supabase.sql
# 4. FÃ¼ge ihn in den SQL Editor ein und klicke "RUN"
```

Das Schema erstellt automatisch:
- ðŸ“Š **AQEA Entries** - Haupttabelle fÃ¼r alle SpracheintrÃ¤ge
- ðŸ“¦ **Work Units** - Verteilte Arbeitseinheiten fÃ¼r Worker
- ðŸ‘¥ **Worker Status** - Live-Tracking aller Worker
- ðŸ·ï¸ **Address Allocations** - Verhindert AQEA-Adress-Kollisionen
- ðŸ“ˆ **Statistics** - Performance-Monitoring und Dashboard-Daten

### 3. Environment Variables konfigurieren

```bash
# Kopiere .env.example zu .env
cp .env.example .env

# Editiere .env mit deinen Supabase-Details:
nano .env
```

**Erforderliche Variablen:**
```bash
# Supabase Connection (aus Project Settings > Database)
DATABASE_URL=postgresql://postgres:YOUR_PASSWORD@db.YOUR_PROJECT.supabase.co:5432/postgres?sslmode=require

# Oder einzelne Komponenten:
DB_HOST=db.YOUR_PROJECT.supabase.co
DB_PASSWORD=YOUR_PASSWORD
DB_DATABASE=postgres
DB_USERNAME=postgres
```

### 4. Verbindung testen

```bash
# Test der Supabase-Integration
python scripts/test-supabase.py
```

**Erwartete Ausgabe:**
```
ðŸš€ AQEA Supabase Integration Test Suite
ðŸ”Œ Testing Supabase database connection...
âœ… Database connection successful!

ðŸ‘¥ Testing worker registration...
âœ… Worker registration successful!
âœ… Worker heartbeat update successful!

ðŸ“¦ Testing work unit management...
âœ… Retrieved work unit: de_wiktionary_01
   Range: A-E
   Estimated entries: 160,000
âœ… Work progress update successful!
âœ… Work unit completion successful!

ðŸŽ‰ Supabase integration test suite completed!
```

## ðŸš€ **System mit Supabase starten**

### Lokaler Test (Single Worker)

```bash
# Terminal 1: Master starten
python -m src.main start-master --language de --workers 2 --source wiktionary

# Terminal 2: Worker starten  
python -m src.main start-worker --worker-id worker-001 --master-host localhost --master-port 8080

# Terminal 3: Status prÃ¼fen
python -m src.main status --master-host localhost --master-port 8080
```

### Multi-Cloud Deployment

```bash
# 1. Erstelle .env-Dateien fÃ¼r jeden Cloud-Provider
# 2. Deploy Worker auf verschiedenen Providern:

# Hetzner (Deutschland)
export DATABASE_URL="postgresql://postgres:..."
python -m src.main start-worker --worker-id hetzner-worker-001 --master-host MASTER_IP

# DigitalOcean (Frankfurt) 
export DATABASE_URL="postgresql://postgres:..."
python -m src.main start-worker --worker-id do-worker-001 --master-host MASTER_IP

# Alle schreiben in dieselbe Supabase-Datenbank! ðŸŽ‰
```

## ðŸ“Š **Live-Monitoring Ã¼ber Supabase**

### Dashboard-Queries

**Aktueller Fortschritt:**
```sql
SELECT 
    SUM(estimated_entries) as total_estimated,
    SUM(entries_processed) as total_processed,
    ROUND(SUM(entries_processed)::float / SUM(estimated_entries) * 100, 2) as progress_percent
FROM work_units;
```

**Worker-Status:**
```sql
SELECT 
    worker_id,
    status,
    current_work_id,
    total_processed,
    last_heartbeat
FROM worker_status 
ORDER BY last_heartbeat DESC;
```

**AQEA-EintrÃ¤ge pro Sprache:**
```sql
SELECT 
    lang_ui,
    COUNT(*) as entries_count,
    COUNT(DISTINCT substring(address from 1 for 7)) as categories_used
FROM aqea_entries 
GROUP BY lang_ui 
ORDER BY entries_count DESC;
```

### Real-time Updates mit Supabase Realtime

```typescript
// FÃ¼r Web-Dashboard (optional)
const { data, error } = await supabase
  .from('work_units')
  .select('*')
  .on('UPDATE', payload => {
    console.log('Work unit updated:', payload)
    updateDashboard(payload.new)
  })
  .subscribe()
```

## ðŸ”§ **Erweiterte Konfiguration**

### Connection Pooling fÃ¼r High Performance

```yaml
# config/cloud-database.yml
database:
  provider: "supabase"
  pool_size: 50        # FÃ¼r viele Worker
  max_overflow: 100
  pool_timeout: 30
  pool_recycle: 3600
```

### Automatische Backups

```sql
-- Supabase erstellt automatisch tÃ¤glich Backups
-- ZusÃ¤tzliche Sicherung der AQEA-EintrÃ¤ge:
pg_dump -h db.YOUR_PROJECT.supabase.co -U postgres -t aqea_entries > aqea_backup.sql
```

### Skalierung & Performance

**FÃ¼r groÃŸe Extraktionen (> 1M EintrÃ¤ge):**

1. **Upgrade Supabase Plan:**
   - Free: Bis 500MB (ca. 100k EintrÃ¤ge)
   - Pro ($25/Monat): Bis 8GB (ca. 2M EintrÃ¤ge)  
   - Team ($599/Monat): Bis 100GB (ca. 25M EintrÃ¤ge)

2. **Database Optimierung:**
   ```sql
   -- ZusÃ¤tzliche Indizes fÃ¼r groÃŸe Datasets
   CREATE INDEX CONCURRENTLY idx_aqea_entries_created_hour 
   ON aqea_entries (date_trunc('hour', created_at));
   
   CREATE INDEX CONCURRENTLY idx_work_units_processing_rate 
   ON work_units (processing_rate) WHERE status = 'processing';
   ```

3. **Worker-Konfiguration:**
   ```yaml
   # FÃ¼r High-Throughput
   performance:
     db_batch_size: 200      # GrÃ¶ÃŸere Batches
     commit_frequency: 100   # HÃ¤ufigere Commits
   ```

## ðŸŽ¯ **Produktions-Deployment Checklist**

- [ ] âœ… Supabase Projekt mit Backup-Policy erstellt
- [ ] âœ… `scripts/init-supabase.sql` erfolgreich ausgefÃ¼hrt  
- [ ] âœ… DATABASE_URL in allen Worker-Umgebungen gesetzt
- [ ] âœ… `scripts/test-supabase.py` erfolgreich durchgelaufen
- [ ] âœ… Row Level Security (RLS) Policies konfiguriert
- [ ] âœ… Monitoring Dashboard eingerichtet
- [ ] âœ… Worker auf verschiedenen Cloud-Providern deployed
- [ ] âœ… AQEA-Adressen werden korrekt alloziert (keine Duplikate)

## ðŸš¨ **Troubleshooting**

### HÃ¤ufige Fehler

**1. Connection refused:**
```bash
# PrÃ¼fe DATABASE_URL Format
echo $DATABASE_URL
# Sollte sein: postgresql://postgres:password@db.project.supabase.co:5432/postgres?sslmode=require
```

**2. SSL-Probleme:**
```bash
# Supabase erfordert SSL
# FÃ¼ge ?sslmode=require zum Ende der DATABASE_URL hinzu
```

**3. Worker kÃ¶nnen keine Work Units bekommen:**
```sql
-- PrÃ¼fe Work Units Status
SELECT work_id, status, assigned_worker FROM work_units;

-- Reset falls nÃ¶tig
UPDATE work_units SET status = 'pending', assigned_worker = NULL WHERE status = 'assigned';
```

**4. AQEA-Adressen-Kollisionen:**
```sql
-- PrÃ¼fe Adress-Allokationen
SELECT category_key, COUNT(*) as allocated_count 
FROM address_allocations 
GROUP BY category_key 
ORDER BY allocated_count DESC;
```

## ðŸŽ‰ **NÃ¤chste Schritte**

Nach erfolgreichem Supabase-Setup:

1. **Multi-Cloud Workers starten:** [README-CLOUD.md](README-CLOUD.md)
2. **Performance Monitoring:** [monitoring/dashboard.md](monitoring/dashboard.md)  
3. **Cost Optimization:** [docs/cost-analysis.md](docs/cost-analysis.md)

**ðŸš€ Ihr AQEA System ist bereit fÃ¼r die groÃŸskalige verteilte Extraktion!** 