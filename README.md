# AQEA Distributed Extractor

**Distributed data extraction system for AQEA (Universal Knowledge Database)**

Automatically extracts and processes language data from multiple sources (Wiktionary, PanLex, Wikidata) using a distributed cloud architecture.

## ğŸ¯ **Features**

- **Multi-Source Support**: Wiktionary, PanLex, Wikidata Lexemes, MusicBrainz
- **Distributed Processing**: Horizontal scaling across multiple cloud servers  
- **API-Limit Friendly**: Different IPs to avoid rate limiting
- **Real-Time Monitoring**: Progress tracking and performance metrics
- **AQEA Integration**: Direct output to AQEA 4-byte address format
- **Cloud-Ready**: Docker containers with one-click deployment

## ğŸ“Š **Performance**

| Language | Estimated Entries | Single Server Time | 5 Servers Time | Cost (5 servers) |
|----------|-------------------|-------------------|-----------------|------------------|
| German   | 800,000          | 4.6 days          | 22 hours        | ~12 CHF          |
| English  | 6,000,000        | 34.7 days         | 6.9 days        | ~90 CHF          |
| French   | 4,000,000        | 23.1 days         | 4.6 days        | ~60 CHF          |
| Spanish  | 1,000,000        | 5.8 days          | 28 hours        | ~15 CHF          |

## ğŸ—ï¸ **Architecture**

```
Master Coordinator  â†â†’  Worker 1 (A-E entries)
        â†•               Worker 2 (F-J entries)  
PostgreSQL DB       â†â†’  Worker 3 (K-O entries)
        â†•               Worker 4 (P-T entries)
Web Dashboard       â†â†’  Worker 5 (U-Z entries)
```

## ğŸš€ **Quick Start**

### Local Development
```bash
# Clone repository
git clone https://github.com/your-username/aqea-distributed-extractor.git
cd aqea-distributed-extractor

# Start local cluster
docker-compose up -d

# Monitor progress
curl http://localhost:8080/api/status
```

### Cloud Deployment (Hetzner)
```bash
# Deploy 5 servers for German extraction
./scripts/deploy.sh hetzner 5 de

# Monitor distributed progress
./scripts/status.sh
```

## ğŸ“ **Project Structure**

```
aqea-distributed-extractor/
â”œâ”€â”€ README.md
â”œâ”€â”€ docker-compose.yml
â”œâ”€â”€ Dockerfile
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ coordinator/          # Master coordination logic
â”‚   â”œâ”€â”€ workers/             # Worker extraction processes
â”‚   â”œâ”€â”€ data_sources/        # Wiktionary, PanLex, etc. integrations
â”‚   â”œâ”€â”€ monitoring/          # Progress tracking and metrics
â”‚   â”œâ”€â”€ aqea/               # AQEA format conversion
â”‚   â””â”€â”€ utils/              # Shared utilities
â”œâ”€â”€ config/
â”‚   â”œâ”€â”€ languages.yml       # Language-specific configurations
â”‚   â”œâ”€â”€ sources.yml         # Data source configurations  
â”‚   â””â”€â”€ deployment.yml      # Cloud deployment settings
â”œâ”€â”€ scripts/
â”‚   â”œâ”€â”€ deploy.sh           # Automated cloud deployment
â”‚   â”œâ”€â”€ status.sh           # Status monitoring
â”‚   â””â”€â”€ cleanup.sh          # Resource cleanup
â”œâ”€â”€ tests/
â””â”€â”€ docs/
    â”œâ”€â”€ API.md              # API documentation
    â”œâ”€â”€ DEPLOYMENT.md       # Deployment guide
    â””â”€â”€ CONTRIBUTING.md     # Development guide
```

## ğŸ› ï¸ **Installation**

### Prerequisites
- Docker & Docker Compose
- Python 3.11+
- PostgreSQL (for local development)

### Dependencies
```bash
pip install -r requirements.txt
```

Main dependencies:
- `aiohttp` - Async HTTP client/server
- `asyncpg` - PostgreSQL async driver  
- `psycopg2-binary` - PostgreSQL sync driver
- `requests` - HTTP requests for APIs
- `beautifulsoup4` - HTML parsing
- `click` - CLI framework

## ğŸ“ **Usage Examples**

### Start German Extraction (Local)
```bash
python -m src.main --language de --workers 3 --source wiktionary
```

### Cloud Deployment
```bash
# Deploy to Hetzner Cloud (5 servers)
./scripts/deploy.sh hetzner 5 de

# Check status
./scripts/status.sh hetzner

# Cleanup when done
./scripts/cleanup.sh hetzner
```

### API Usage
```bash
# Get extraction status
GET http://your-master-ip:8080/api/status

# Start new extraction
POST http://your-master-ip:8080/api/extract
{
  "language": "de",
  "source": "wiktionary",
  "workers": 5
}
```

## ğŸŒ **Supported Data Sources**

| Source | Format | Entries | License | API Limits |
|--------|--------|---------|---------|------------|
| **Wiktionary** | MediaWiki API | 8.4M+ | CC-BY-SA | 5000/hour/IP |
| **PanLex** | Bulk Download | 80GB | CC0 | None (bulk) |
| **Wikidata Lexemes** | SPARQL/Dumps | 3GB | CC0 | 5000/min |
| **MusicBrainz** | REST API | 40GB | CC0-PD | 1/sec |

## ğŸ“ˆ **Monitoring & Metrics**

Real-time dashboard shows:
- **Progress**: Percentage completed per language
- **Performance**: Entries processed per minute per worker
- **Health**: Worker status and error rates  
- **Costs**: Current cloud spending
- **ETA**: Estimated completion time

## âš™ï¸ **Configuration**

### Language Configuration (`config/languages.yml`)
```yaml
languages:
  de:
    name: "German"
    estimated_entries: 800000
    alphabet_ranges:
      - { start: "A", end: "E", weight: 0.2 }
      - { start: "F", end: "J", weight: 0.15 }
      # ...
  en:
    name: "English"  
    estimated_entries: 6000000
    # ...
```

### Cloud Provider Configuration (`config/deployment.yml`)
```yaml
providers:
  hetzner:
    master_type: "cx21"    # 2 vCPU, 4GB RAM
    worker_type: "cx11"    # 1 vCPU, 2GB RAM  
    cost_per_hour: 0.015   # EUR
    regions: ["nbg1", "fsn1"]
```

## ğŸ”§ **Development**

### Run Tests
```bash
pytest tests/
```

### Add New Data Source
1. Create `src/data_sources/your_source.py`
2. Implement `DataSourceInterface`
3. Add configuration to `config/sources.yml`
4. Update tests

### Local Development Setup
```bash
# Start PostgreSQL
docker run -d --name postgres -e POSTGRES_PASSWORD=aqea -p 5432:5432 postgres:15

# Install dependencies
pip install -r requirements.txt

# Run coordinator locally
python -m src.coordinator.main --mode development
```

## ğŸ“Š **Cost Analysis**

**Hetzner Cloud (5 servers for German):**
- 1x CX21 Master: â‚¬0.031/hour Ã— 24h = â‚¬0.74
- 5x CX11 Workers: â‚¬0.015/hour Ã— 24h Ã— 5 = â‚¬1.80
- **Total: â‚¬2.54/day** for 800K German entries

**vs. Local Processing:**
- Laptop blocked for 4.6 days
- Opportunity cost: ~â‚¬100-200
- **ROI: 40-80x better with cloud**

## ğŸ¤ **Contributing**

1. Fork the repository
2. Create feature branch (`git checkout -b feature/amazing-feature`)
3. Commit changes (`git commit -m 'Add amazing feature'`)
4. Push to branch (`git push origin feature/amazing-feature`)
5. Open Pull Request

## ğŸ“„ **License**

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

## ğŸ™ **Acknowledgments**

- **AQEA Framework** - Universal knowledge database format
- **Wikimedia Foundation** - Wiktionary and Wikidata
- **PanLex Project** - Multilingual lexical database
- **Cloud Providers** - Hetzner, DigitalOcean for affordable compute

## ğŸ“ **Support**

- ğŸ“§ Email: your-email@domain.com
- ğŸ› Issues: [GitHub Issues](https://github.com/your-username/aqea-distributed-extractor/issues)
- ğŸ’¬ Discord: [AQEA Community](https://discord.gg/aqea)

---

**Ready to extract millions of language entries? Let's go! ğŸš€** 